{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "import pandas as pd\n",
    "from termcolor import colored\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "import json\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.stats import spearmanr\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import glob\n",
    "import os.path\n",
    "import numpy as np\n",
    "import sys\n",
    "import codecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(text,shrink=False):\n",
    "    text=text.lower()\n",
    "    text = re.sub(r'^https?:\\/\\/.*[\\r\\n]*', '', text, flags=re.MULTILINE)\n",
    "    text=re.sub('[“\"”]',' \" ',text)\n",
    "    retain='[^abcdefghijklmnopqrstuvwxyz!#?\" ]'\n",
    "    text=re.sub('[()–-]',' ',text)\n",
    "    text=re.sub(retain,'',text)\n",
    "    text=text.replace('?',' ? ')\n",
    "    text=text.replace('#',' # ')\n",
    "    text=text.replace('!',' ! ')\n",
    "    text=text.split()\n",
    "    Lemmatizer=WordNetLemmatizer()\n",
    "    Stemmer=PorterStemmer()\n",
    "    if shrink:    \n",
    "        text=[Stemmer.stem(Lemmatizer.lemmatize(word, pos='v')) for word in text]\n",
    "    return ' '.join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory='datasets/train-task2-TC.labels'\n",
    "props_=open(directory).read().split('\\n')[:-1]\n",
    "sentences,Articles, labels=[],[],[]\n",
    "IDS=[]\n",
    "Spans=[]\n",
    "for prop in props_:\n",
    "    prop_=prop.split('\\t')\n",
    "    x,y=int(prop_[2]),int(prop_[3])\n",
    "    Spans.append((x,y))\n",
    "    sentences.append([open('datasets/train-articles/article{}.txt'.format(prop_[0])).read()[:x],open('datasets/train-articles/article{}.txt'.format(prop_[0])).read()[x:y],open('datasets/train-articles/article{}.txt'.format(prop_[0])).read()[y:]])\n",
    "    Articles.append(open('datasets/train-articles/article{}.txt'.format(prop_[0])).read())\n",
    "    labels.append(prop_[1])\n",
    "    IDS.append(prop_[0])\n",
    "    ids=int(prop_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind=2\n",
    "def gen(ind):\n",
    "    print(labels[ind])\n",
    "    pre=colored(sentences[ind][0], color='green')\n",
    "    sen=colored(sentences[ind][1], color='red')\n",
    "    post=colored(sentences[ind][-1], color='green')\n",
    "    print(pre+sen+post)\n",
    "def span_read(id,span):\n",
    "    return open('datasets/train-articles/article{}.txt'.format(id)).read()[span[0]:span[1]]\n",
    "def freq_dict(text,Stem=False):\n",
    "    freq={}\n",
    "    for word in clean(text,Stem).split():\n",
    "        if word in freq:\n",
    "            freq[word]=freq[word]+1\n",
    "        else:\n",
    "            freq[word]=1\n",
    "    return freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Appeal_to_Authority',\n",
       " 'Appeal_to_fear-prejudice',\n",
       " 'Bandwagon,Reductio_ad_hitlerum',\n",
       " 'Black-and-White_Fallacy',\n",
       " 'Causal_Oversimplification',\n",
       " 'Doubt',\n",
       " 'Exaggeration,Minimisation',\n",
       " 'Flag-Waving',\n",
       " 'Loaded_Language',\n",
       " 'Name_Calling,Labeling',\n",
       " 'Repetition',\n",
       " 'Slogans',\n",
       " 'Thought-terminating_Cliches',\n",
       " 'Whataboutism,Straw_Men,Red_Herring'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({'Id':IDS, 'Span':Spans, 'Label':labels})\n",
    "set(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dumps=True\n",
    "if(not dumps):\n",
    "    Stitch=\"\"\n",
    "    for doc in os.listdir('datasets/train-articles'):\n",
    "        Stitch=Stitch+open('datasets/train-articles/'+doc).read()    \n",
    "    f = open(\"dumps/Text_stitch.txt\",\"w\")\n",
    "    f.write(Stitch)\n",
    "    f.close()\n",
    "    corp_freq=dict()\n",
    "    Doc_freqs=dict()\n",
    "    corp_freq=freq_dict(Stitch)\n",
    "    for id in IDS :\n",
    "        txt=open('datasets/train-articles/article{}.txt'.format(id)).read()\n",
    "        Doc_freqs[id]=freq_dict(txt)\n",
    "\n",
    "    corp_freq_json = json.dumps(corp_freq)\n",
    "    f = open(\"dumps/Corp_freq_raw.json\",\"w\")\n",
    "    f.write(corp_freq_json)\n",
    "    f.close()\n",
    "\n",
    "    Doc_freqs_json = json.dumps(Doc_freqs)\n",
    "    f = open(\"dumps/Doc_freqs_raw.json\",\"w\")\n",
    "    f.write(Doc_freqs_json)\n",
    "    f.close()\n",
    "\n",
    "    corp_freq_stem=dict()\n",
    "    Doc_freqs_stem=dict()\n",
    "    corp_freq_stem=freq_dict(Stitch,Stem=True)\n",
    "    for id in IDS :\n",
    "        txt=open('datasets/train-articles/article{}.txt'.format(id)).read()\n",
    "        Doc_freqs_stem[id]=freq_dict(txt,Stem=True)\n",
    "\n",
    "    corp_freq_json_stem = json.dumps(corp_freq_stem)\n",
    "    f = open(\"dumps/Corp_freq_stem.json\",\"w\")\n",
    "    f.write(corp_freq_json_stem)\n",
    "    f.close()\n",
    "\n",
    "    Doc_freqs_json_stem = json.dumps(Doc_freqs_stem)\n",
    "    f = open(\"dumps/Doc_freqs_stem.json\",\"w\")\n",
    "    f.write(Doc_freqs_json_stem)\n",
    "    f.close()\n",
    "\n",
    "try: \n",
    "    Stitch \n",
    "except: \n",
    "    Stitch=open(\"dumps/Text_stitch.txt\",'r').read()\n",
    "try: \n",
    "    corp_freq_raw \n",
    "except: \n",
    "    corp_freq_raw=json.loads(open(\"dumps/Corp_freq_raw.json\",'r').read())\n",
    "try: \n",
    "    Doc_freqs_raw \n",
    "except: \n",
    "    Doc_freqs_raw=json.loads(open(\"dumps/Doc_freqs_raw.json\",'r').read())\n",
    "try: \n",
    "    corp_freq_stem \n",
    "except: \n",
    "    corp_freq_stem=json.loads(open(\"dumps/Corp_freq_stem.json\",'r').read())\n",
    "try: \n",
    "    Doc_freqs_stem \n",
    "except: \n",
    "    Doc_freqs_stem=json.loads(open(\"dumps/Doc_freqs_stem.json\",'r').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad(val):\n",
    "    t_df=df[df['Label']=='Doubt']\n",
    "    t_id,t_Span=t_df['Id'],t_df['Span']\n",
    "    padsent_d=[]\n",
    "    for ids,spans in zip(t_id,t_Span):\n",
    "        padsent_d.append(span_read(ids,(spans[0]-val,spans[1]+val)))\n",
    "\n",
    "    t_df=df[df['Label']!='Doubt']\n",
    "    t_id,t_Span=t_df['Id'],t_df['Span']\n",
    "    padsent=[]\n",
    "    for ids,spans in zip(t_id,t_Span):\n",
    "        padsent.append(span_read(ids,(spans[0]-val,spans[1]+val)))\n",
    "    return padsent_d,padsent\n",
    "padsent_d,padsent=pad(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_res(val,wts):\n",
    "    isin,notin=pad(val)\n",
    "    c_,c1_,c,c1,t,t1=0,0,0,0,0,0\n",
    "    for sent in isin:\n",
    "        t=t+1\n",
    "        cond=False\n",
    "        for check in wts:\n",
    "            if check in clean(sent).split():\n",
    "                cond=True\n",
    "                c_=c_+wts[check]\n",
    "        if cond:\n",
    "            c=c+1\n",
    "    for sent in notin:\n",
    "        t1=t1+1\n",
    "        cond=False\n",
    "        for check in wts:\n",
    "            if check in clean(sent).split():\n",
    "                cond=True\n",
    "                c1_=c1_+wts[check]\n",
    "        if cond:\n",
    "            c1=c1+1\n",
    "    print(c/t,c_/t)\n",
    "    print(c1/t1,c1_/t1)\n",
    "    print((c*t1)/(c1*t),(c_*t1)/(c1_*t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.46169354838709675 1.7580645161290323\n",
      "0.09569215051932572 0.22671547760939895\n",
      "4.8247797325220985 7.7544971109469065\n"
     ]
    }
   ],
   "source": [
    "wts={\n",
    "    '?' : 2.5,\n",
    "    'how' : 1,\n",
    "    'when' : 1,\n",
    "    'where' : 1,\n",
    "    'why' :10,\n",
    "    'while' : 1,\n",
    "    'what' : 1,\n",
    "    'cant' : 1,\n",
    "}\n",
    "print_res(15,wts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['?', 'how', 'when', 'where', 'why', 'while', 'what', 'cant'])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wts.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i-Muslim group Stop Islamization of America.\n",
      "\n",
      "They were due \n",
      " a pro-Israel \"Defeat Jihad\" poster campaig\n",
      "ty of justice.\n",
      "BUILD THE WALL!\"\n",
      "Trump tweeted.\n",
      " new partner.\n",
      "\"Working together, we'll get it taken care of,\" Trump said.\n",
      "\n",
      " remember that liberty of conscience is not up for a vote,” he said.\n",
      "\n",
      "Tr\n",
      "th the phrase “Israel must be wiped out” emblazoned on \n",
      "enly calls for “Death to Israel” and labels the\n",
      "g “David Duke, a man to believe in!”\n",
      "In July 2010,\n",
      " Opposing BDS\n",
      "\n",
      "First they came for the Jews.\n",
      "And then they came for everyone else.\n",
      "Jewish studen\n",
      " followers to “punch a Zionist today.” It is unclea\n",
      " light of his “punch a Zionist” tweet calling\n",
      "erred to as a “sex trade on Capitol Hill.”\n",
      "The American p\n",
      ", this is now.\n",
      "I’m no longer afraid.\n",
      "When the story \n",
      "erred to as a “sex trade on Capitol Hill.”\n",
      "Do you want to\n",
      "ers.\n",
      "I believe today is a day of vindication for the rights of immigrants.”\n",
      "Alex Bastian of\n",
      "rtist to spray SMASH THE STATE on his office \n",
      ", ni tontos,” (Neither lefties nor stupid).\n",
      "The jab cert\n",
      "rend Jeremiah “God damn America) Wright who bl\n",
      "s “David Duke, a man to believe in!”\n",
      "By inviting pe\n",
      " this movement—Stay in the fight!\n",
      "Keep the Faith.\n",
      "Never surrender!\n",
      "This address al\n",
      "arts, saying: “punch a zionist.”\n",
      "Among the me\n",
      "day he gave a \"Hungary First\" speech in whi\n",
      " on Facebook.\n",
      "\"For us, Hungary is first.\n",
      "We will fight\n",
      "about putting \"America First.\"\n",
      "\"The preside\n",
      "aised Duke, as “David Duke, a man to believe in!”\n",
      "Besides postin\n",
      "tedly shouted, “We are Hamas” and “Let’s go \n",
      "are Hamas” and “Let’s go Hamas.” After the rall\n",
      " first is our 'Stop Soros' law.\"\n",
      "Orban h\n",
      "tian nations.\n",
      "\"Christianity is Europe's last hope,\" Orban told a\n",
      " from Africa, \"our worst nightmares can come true.\n",
      "The West fall\n",
      "ime Minister: ‘Christianity is Europe’s last hope’\n",
      "\n",
      "NewsFaith, P\n",
      "on Sunday that, “Christianity is Europe's last hope.”\n",
      "Addressing his\n",
      "le in Budapest, “Christianity is Europe’s last hope.”\n",
      "He continued by\n",
      " first is our ‘Stop Soros’ law.”\n",
      "Orban h\n",
      "rrakhan Speech: 'Jews Are My Enemy,' 'White Folks Ar\n",
      "audience that \"powerful Jews are my enemy,\" and \"white fol\n",
      "un violence.\n",
      "“‘Take the guns first, go through due process second,’ Trump said.\n",
      "\n",
      " Dem Rep Over \"Jewish Question\"\n",
      "\n",
      "Anti-Israel \n",
      "entioning the \"Jewish question.\"\n",
      "Democratic I\n",
      "ttacks, saying white people “deserve to die” and praising \n",
      " white people “deserve to die” and praising A\n",
      "and screaming “Allahu akbar.” Sean Ragan m\n",
      "lah and Islam.\n",
      "Allahu akbar.”\n",
      "Of course, e\n",
      "f Iranians for Free Iran.\n",
      "“There is a v\n",
      "e East policy!\n",
      "That’s the real threat!\n",
      "Article posted \n",
      "ut in my book, Stop the Islamization of America: A Practical G\n",
      "named federal “Gun-Free Schools” law leaves sc\n",
      "rmy went home, \"America First\" had a new appe\n",
      "ggressors and \"end tyranny in our world.\"\n",
      "That GOP set\n",
      "tly declared, \"Extremism in the defense of liberty is no vice,\" and then wen\n",
      "o believe that \"discretion is the better part of valor.\"\n",
      "Sen. Bob Corker\n",
      "racy crusades \"to end tyranny in our world\" accomplish?\n",
      "T\n",
      "that there was No Collusion!\"\n",
      "\n",
      "eople to chant “Death to America” in mosques eve\n",
      "o better way to keep the Catholic family together and committed \n",
      " gun sales and Red Flag Laws save lives,” said Karen F\n",
      " is the Trump, \"Take the guns first and then due process\" mantra.\n",
      "Guns.c\n",
      "f David Hogg's #NeverAgain movement, \"WHE\n",
      " our in-boxes.\n",
      "Long live the Fifth Estate!”\n",
      "Eventually a\n",
      "ly proclaimed, Americans no longer have to fear North Korea and can sleep \n",
      "ple,” he said.\n",
      "“We want children staying together,” Trump said, bl\n",
      "gration Plan\": Illegals Have To Go!\n",
      "\n",
      "On Monday, Pr\n",
      " was wearing a “Make America Great Again” hat.\n",
      "The incid\n",
      "rom his head.\n",
      "\"I support my President and, if you do\n",
      " For Wearing A MAGA Hat At Whatabu\n",
      "earing a MAGA (Make America Great Again) hat.\n",
      "The moth\n",
      "f them wore a “Make American Great Again” hat, KENS5 re\n",
      "s by News4SA.\n",
      "“I support my President and if you don\n",
      "o was wearing a #MAGA hat.\n",
      "The crimi\n",
      "\n",
      "THIS BAR IS A SAFE SPACE FOR EVERYONE!\n",
      "No matter you\n",
      "ty stands for.\n",
      "We are not violent.\n",
      "We do not tak\n",
      "ng people that abortion is murder and that 58 mil\n",
      "ve taught that homosexuality is an abomination, and how it is\n",
      "\n",
      "ng forward and I have faith in our president,” Susie Hammon\n",
      "\n",
      " get him a new #maga hat… SIGNED by\n",
      " was wearing a “Make America Great Again” hat while enjo\n",
      "selling book, “Trump’s America: The Truth Abou\n",
      "evolution was “No King but King Jesus.” America’s or\n",
      "onal seal was “REBELLION TO TYRANTS IS OBEDIENCE TO GOD” with a pictur\n",
      " and declared “Resistance to tyrants is obedience to God!\"\n",
      "Furthermore,\n",
      "e the People.”\n",
      "Representatives work for us, we do not work for them.\n",
      "“They are end\n",
      " good priests?\n",
      "Then it’s up to us.\n",
      "The Vatican w\n",
      "\"Allah Akbar\".\n",
      "Long live Hitler, to death the Jews. \"\n",
      "It can't be\n",
      "lerical ranks.\n",
      "#StopTheSynod.\n",
      "It has all th\n",
      "Church is now.\n",
      "Expose and rout every last predator.\n",
      "Purge every ho\n",
      "last predator.\n",
      "Purge every homosexual from its clerical ranks.\n",
      "#StopTheSynod\n",
      "oglio plot to “reform the Church.” Now we know \n",
      " we know what “reform the Church” looks like in\n",
      "he last straw.\n",
      "All credibility is lost.\n",
      "The October S\n",
      "August 1, 2018\n",
      "Enough is enough!!!\n",
      "This is jus\n",
      "tice required “life for life, eye for eye, tooth for tooth, hand for hand, foot for foot” (Deut.\n",
      "19:21)\n",
      " shalt require life for life, eye for eye, tooth for tooth, hand for hand, foot for foot” (Deut.\n",
      "19:19-\n",
      "ld be, because power respects power.\n",
      "The New York \n",
      "nce is golden.\n",
      "In the world of human rights, silence equals mass murder.\n",
      "They say you \n",
      "ave shown that no one can be above the law, regardless of rank or privilege.\n",
      "I was gratefu\n",
      "n the fight to DEFEND BISHOP MORLINO last year.\n",
      "\"If\n",
      "nate the news.\n",
      "May God bless and keep Bishop Robert Morlino.\n",
      "MJM\n",
      "Bishop Ro\n",
      "am not alone — I am tired of this.\n",
      "I am tired of\n",
      " my household, we will serve the Lord.”\n",
      "Faithfully y\n",
      " on the Youth, #StopThe Synod2018\n",
      "\n",
      "During the la\n",
      "unched its own #StopTheSynod petition, for \n",
      "he Petition to Stop the Synod Here.\n",
      "\n",
      "Editor's Not\n",
      "he Church.\n",
      "But we will.\n",
      "Christ promis\n",
      "an inheritance:Do not be afraid!\n",
      "Do not be afr\n",
      "ing headline: “Pope Francis Must Resign.”\n",
      "Nearly three\n",
      "ical disorder.\n",
      "Kill the Messenger\n",
      "I suspect that\n",
      "aw).\n",
      "2.\n",
      "Scrap “Countering Violent Extremism.”\n",
      "“Countering \n",
      "t Extremism.”\n",
      "“Countering Violent Extremism” is the pathet\n",
      "security.\n",
      "The “Countering Violent Extremism” is trash and \n",
      "iscarding the “Countering Violent Extremism” absurdity, a \n",
      "woman in a red Make America Great Again hat and “Latino\n",
      "Again hat and “Latinos for Trump” sign.\n",
      "The sto\n",
      " things, that “Trump is dead” because of La\n",
      " the election “to Googlers and beyond.”\n",
      "President Tr\n",
      "ute attempt at character assassination, and there sho\n",
      "he Last-Minute Character Assassination of Judge Kavana\n",
      "owest level of character assassination yet.\n",
      "They have \n",
      "high school to assassinate Judge Kavanaugh’s character.\n",
      "They have don\n",
      "e.\n",
      "This isn’t “boys will be boys.” Actions have\n",
      "n promising to Drain the Swamp so popular.\n",
      "The\n",
      "o-holds barred character assassination.\n",
      "\n",
      "While Judge \n",
      "ss campaign of character assassination, they want to \n",
      "writer called “Kavanaugh Derangement Syndrome.\"\n",
      "Senator Kirs\n",
      "nother case of Kavanaugh Derangement Syndrome.\n",
      "Let’s assume \n",
      "the smears and character assassination, President Tru\n",
      ".\n",
      "So much for “I am woman, hear me roar.”\n",
      "Grassley sho\n",
      " eleventh-hour character-assassination attempts may be\n",
      "eir efforts at character assassination.\n",
      "President Tru\n",
      "d with Trump’s “America first” approach to fo\n",
      "khan In Iran: “Death to America!” – America Is The “Great Satan”\n",
      "\n",
      "Ah yes, Nati\n",
      "Iran chanting “Death to America” in Arabic and\n",
      "slam chanting \"Death to America\" Farrakhan [in\n",
      "he Sanctions, \"Victory Will Be Yours.\"\n",
      "pic.twitter.\n",
      "akhan chanted “Death to America” and claimed t\n",
      "y looks like – no climbers anymore under our Administration!”\n",
      "Here’s some \n",
      " minutes.\n",
      "Also the Left killed comedy.\n",
      "This is what \n"
     ]
    }
   ],
   "source": [
    "for row in df[df['Label']=='Slogans'].values:\n",
    "    print(span_read(row[0],(row[1][0]-15,row[1][1]+15)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['111111112', (191, 221), 'Slogans'],\n",
       "       ['111111112', (785, 798), 'Slogans'],\n",
       "       ['111111113', (5775, 5791), 'Slogans'],\n",
       "       ['111111131', (2953, 2997), 'Slogans'],\n",
       "       ['111111132', (12045, 12087), 'Slogans'],\n",
       "       ['698503276', (3107, 3132), 'Slogans'],\n",
       "       ['701225819', (3787, 3804), 'Slogans'],\n",
       "       ['701225819', (1967, 1987), 'Slogans'],\n",
       "       ['701553469', (77, 143), 'Slogans'],\n",
       "       ['701553469', (3455, 3476), 'Slogans'],\n",
       "       ['704591553', (2765, 2780), 'Slogans'],\n",
       "       ['707451080', (1629, 1656), 'Slogans'],\n",
       "       ['707772906', (1363, 1385), 'Slogans'],\n",
       "       ['708561738', (2291, 2318), 'Slogans'],\n",
       "       ['711566593', (1381, 1442), 'Slogans'],\n",
       "       ['713130996', (1783, 1798), 'Slogans'],\n",
       "       ['725498022', (6105, 6131), 'Slogans'],\n",
       "       ['725731328', (547, 563), 'Slogans'],\n",
       "       ['728169864', (5753, 5774), 'Slogans'],\n",
       "       ['728972961', (1400, 1452), 'Slogans'],\n",
       "       ['729651527', (2760, 2775), 'Slogans'],\n",
       "       ['729668796', (238, 251), 'Slogans'],\n",
       "       ['729668796', (476, 500), 'Slogans'],\n",
       "       ['729668796', (815, 828), 'Slogans'],\n",
       "       ['730149656', (3070, 3104), 'Slogans'],\n",
       "       ['730149656', (3832, 3846), 'Slogans'],\n",
       "       ['730149656', (3851, 3868), 'Slogans'],\n",
       "       ['731927633', (2434, 2444), 'Slogans'],\n",
       "       ['731927633', (1019, 1053), 'Slogans'],\n",
       "       ['731927633', (1190, 1224), 'Slogans'],\n",
       "       ['732154721', (27, 61), 'Slogans'],\n",
       "       ['732154721', (280, 318), 'Slogans'],\n",
       "       ['732610971', (433, 472), 'Slogans'],\n",
       "       ['732610971', (2014, 2024), 'Slogans'],\n",
       "       ['736231219', (17, 39), 'Slogans'],\n",
       "       ['736231219', (285, 313), 'Slogans'],\n",
       "       ['737194975', (1142, 1192), 'Slogans'],\n",
       "       ['737255982', (46, 61), 'Slogans'],\n",
       "       ['737255982', (606, 621), 'Slogans'],\n",
       "       ['737255982', (860, 888), 'Slogans'],\n",
       "       ['740356006', (374, 389), 'Slogans'],\n",
       "       ['741923579', (3356, 3368), 'Slogans'],\n",
       "       ['741923579', (1641, 1653), 'Slogans'],\n",
       "       ['755393220', (2380, 2389), 'Slogans'],\n",
       "       ['755814432', (3938, 3962), 'Slogans'],\n",
       "       ['758756657', (481, 513), 'Slogans'],\n",
       "       ['761546223', (225, 241), 'Slogans'],\n",
       "       ['761610997', (1977, 1992), 'Slogans'],\n",
       "       ['761610997', (640, 664), 'Slogans'],\n",
       "       ['761674108', (539, 585), 'Slogans'],\n",
       "       ['761674108', (906, 948), 'Slogans'],\n",
       "       ['761674108', (2424, 2451), 'Slogans'],\n",
       "       ['761780613', (887, 899), 'Slogans'],\n",
       "       ['762340819', (3284, 3302), 'Slogans'],\n",
       "       ['763440871', (3253, 3287), 'Slogans'],\n",
       "       ['763761219', (116, 140), 'Slogans'],\n",
       "       ['765913191', (5077, 5119), 'Slogans'],\n",
       "       ['765913191', (601, 612), 'Slogans'],\n",
       "       ['765982381', (6856, 6882), 'Slogans'],\n",
       "       ['766942310', (2081, 2125), 'Slogans'],\n",
       "       ['767129999', (2058, 2094), 'Slogans'],\n",
       "       ['767129999', (59, 79), 'Slogans'],\n",
       "       ['769682854', (253, 279), 'Slogans'],\n",
       "       ['769682854', (1004, 1026), 'Slogans'],\n",
       "       ['769752554', (45, 49), 'Slogans'],\n",
       "       ['769752554', (159, 183), 'Slogans'],\n",
       "       ['769752554', (392, 417), 'Slogans'],\n",
       "       ['769752554', (1919, 1941), 'Slogans'],\n",
       "       ['769962236', (206, 212), 'Slogans'],\n",
       "       ['769962236', (2200, 2223), 'Slogans'],\n",
       "       ['769962236', (3260, 3278), 'Slogans'],\n",
       "       ['769962328', (2086, 2105), 'Slogans'],\n",
       "       ['769962328', (2338, 2369), 'Slogans'],\n",
       "       ['770156173', (0, 18), 'Slogans'],\n",
       "       ['770877978', (3117, 3146), 'Slogans'],\n",
       "       ['771546417', (13, 17), 'Slogans'],\n",
       "       ['771546417', (1158, 1163), 'Slogans'],\n",
       "       ['771546417', (114, 140), 'Slogans'],\n",
       "       ['772947654', (5653, 5669), 'Slogans'],\n",
       "       ['773520636', (2131, 2153), 'Slogans'],\n",
       "       ['773520636', (2194, 2234), 'Slogans'],\n",
       "       ['773520636', (2032, 2073), 'Slogans'],\n",
       "       ['773520636', (3446, 3498), 'Slogans'],\n",
       "       ['773937361', (16081, 16099), 'Slogans'],\n",
       "       ['774007496', (493, 528), 'Slogans'],\n",
       "       ['776049384', (10722, 10735), 'Slogans'],\n",
       "       ['776049384', (10637, 10673), 'Slogans'],\n",
       "       ['776049384', (10674, 10720), 'Slogans'],\n",
       "       ['776049384', (2292, 2309), 'Slogans'],\n",
       "       ['776049384', (2330, 2347), 'Slogans'],\n",
       "       ['776049384', (7146, 7169), 'Slogans'],\n",
       "       ['776368676', (2017, 2033), 'Slogans'],\n",
       "       ['777488669', (2625, 2698), 'Slogans'],\n",
       "       ['777488669', (8903, 8976), 'Slogans'],\n",
       "       ['778139122', (10786, 10806), 'Slogans'],\n",
       "       ['778139122', (11820, 11876), 'Slogans'],\n",
       "       ['778664280', (4787, 4847), 'Slogans'],\n",
       "       ['780414700', (866, 887), 'Slogans'],\n",
       "       ['780414700', (2286, 2330), 'Slogans'],\n",
       "       ['780414700', (2944, 2962), 'Slogans'],\n",
       "       ['780414700', (18812, 18834), 'Slogans'],\n",
       "       ['780619695', (44, 62), 'Slogans'],\n",
       "       ['780619695', (6301, 6314), 'Slogans'],\n",
       "       ['780619695', (6232, 6251), 'Slogans'],\n",
       "       ['782017101', (7573, 7580), 'Slogans'],\n",
       "       ['782086447', (39477, 39493), 'Slogans'],\n",
       "       ['783702663', (29165, 29189), 'Slogans'],\n",
       "       ['783702663', (6236, 6254), 'Slogans'],\n",
       "       ['785801366', (2198, 2226), 'Slogans'],\n",
       "       ['785801366', (2230, 2258), 'Slogans'],\n",
       "       ['785801366', (2948, 2976), 'Slogans'],\n",
       "       ['785801366', (3686, 3714), 'Slogans'],\n",
       "       ['786527921', (11260, 11285), 'Slogans'],\n",
       "       ['786527921', (11294, 11311), 'Slogans'],\n",
       "       ['786527921', (10254, 10267), 'Slogans'],\n",
       "       ['786527921', (16846, 16868), 'Slogans'],\n",
       "       ['787142429', (2735, 2758), 'Slogans'],\n",
       "       ['787529309', (16, 40), 'Slogans'],\n",
       "       ['787529309', (323, 347), 'Slogans'],\n",
       "       ['787529309', (7814, 7853), 'Slogans'],\n",
       "       ['787668628', (2408, 2425), 'Slogans'],\n",
       "       ['789121798', (283, 299), 'Slogans'],\n",
       "       ['789370909', (2148, 2171), 'Slogans'],\n",
       "       ['789370909', (4416, 4439), 'Slogans'],\n",
       "       ['789370909', (8985, 9015), 'Slogans'],\n",
       "       ['789370909', (9840, 9870), 'Slogans'],\n",
       "       ['789370909', (11848, 11871), 'Slogans'],\n",
       "       ['789615291', (6697, 6721), 'Slogans'],\n",
       "       ['790266787', (293, 317), 'Slogans'],\n",
       "       ['790677230', (492, 515), 'Slogans'],\n",
       "       ['793921939', (1974, 1989), 'Slogans'],\n",
       "       ['999000675', (44, 92), 'Slogans'],\n",
       "       ['999000675', (225, 241), 'Slogans'],\n",
       "       ['999000675', (544, 560), 'Slogans'],\n",
       "       ['999000675', (1019, 1040), 'Slogans'],\n",
       "       ['999000675', (1205, 1221), 'Slogans'],\n",
       "       ['999001188', (735, 779), 'Slogans'],\n",
       "       ['999001970', (191, 213), 'Slogans']], dtype=object)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['Label']=='Slogans'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping=dict()\n",
    "inv_mapping=dict()\n",
    "c=0\n",
    "for i in set(labels):\n",
    "    mapping[c]=i\n",
    "    inv_mapping[i]=c\n",
    "    c=c+1\n",
    "label=inv_mapping.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_label=dict()\n",
    "label_id=dict()\n",
    "for i,j in zip(IDS,labels):\n",
    "    if i in id_label:\n",
    "        id_label[i].append(j)\n",
    "    else :\n",
    "        id_label[i]=[j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(p_list):\n",
    "    vec=[0]*14\n",
    "    for i in p_list:\n",
    "        vec[inv_mapping[i]]=vec[inv_mapping[i]]+1\n",
    "    return tuple(vec)\n",
    "def b_vectorize(p_list):\n",
    "    return tuple([int(i>0) for i in vectorize(p_list)])\n",
    "\n",
    "data=[]\n",
    "for k,v in id_label.items():\n",
    "    data.append((k,)+vectorize(v))\n",
    "idf=pd.DataFrame(data,columns=['ID']+list(inv_mapping.keys()))\n",
    "idf['length']=idf['ID'].apply(lambda x : len(span_read(x,[0,-1])))\n",
    "\n",
    "b_data=[]\n",
    "for k,v in id_label.items():\n",
    "    b_data.append((k,)+b_vectorize(v))\n",
    "b_idf=pd.DataFrame(b_data,columns=['ID']+list(inv_mapping.keys()))\n",
    "b_idf['length']=b_idf['ID'].apply(lambda x : len(span_read(x,[0,-1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_idf=idf.copy()\n",
    "norm_idf['length']=norm_idf['length']/norm_idf['length'].mean()\n",
    "for cat in norm_idf.columns[1:-1]:\n",
    "    norm_idf[cat]=norm_idf[cat]/norm_idf['length']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Loaded_Language</th>\n",
       "      <th>Slogans</th>\n",
       "      <th>Whataboutism,Straw_Men,Red_Herring</th>\n",
       "      <th>Appeal_to_fear-prejudice</th>\n",
       "      <th>Causal_Oversimplification</th>\n",
       "      <th>Repetition</th>\n",
       "      <th>Appeal_to_Authority</th>\n",
       "      <th>Doubt</th>\n",
       "      <th>Flag-Waving</th>\n",
       "      <th>Name_Calling,Labeling</th>\n",
       "      <th>Exaggeration,Minimisation</th>\n",
       "      <th>Black-and-White_Fallacy</th>\n",
       "      <th>Bandwagon,Reductio_ad_hitlerum</th>\n",
       "      <th>Thought-terminating_Cliches</th>\n",
       "      <th>length</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>111111111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.843858</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.460964</td>\n",
       "      <td>4.921929</td>\n",
       "      <td>2.460964</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.687716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>111111112</td>\n",
       "      <td>5.611769</td>\n",
       "      <td>3.741179</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.87059</td>\n",
       "      <td>3.741179</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.87059</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.835307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>111111113</td>\n",
       "      <td>3.525165</td>\n",
       "      <td>0.881291</td>\n",
       "      <td>0.881291</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.643874</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.762583</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.694205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>111111114</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.619338</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.619338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>111111115</td>\n",
       "      <td>6.870274</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.290091</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.160366</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID  Loaded_Language   Slogans  Whataboutism,Straw_Men,Red_Herring  \\\n",
       "0  111111111         0.000000  0.000000                            0.000000   \n",
       "1  111111112         5.611769  3.741179                            0.000000   \n",
       "2  111111113         3.525165  0.881291                            0.881291   \n",
       "3  111111114         0.000000  0.000000                            0.000000   \n",
       "4  111111115         6.870274  0.000000                            0.000000   \n",
       "\n",
       "   Appeal_to_fear-prejudice  Causal_Oversimplification  Repetition  \\\n",
       "0                  9.843858                   0.000000    2.460964   \n",
       "1                  0.000000                   0.000000    0.000000   \n",
       "2                  0.000000                   2.643874    0.000000   \n",
       "3                  2.619338                   0.000000    0.000000   \n",
       "4                  0.000000                   0.000000    0.000000   \n",
       "\n",
       "   Appeal_to_Authority     Doubt  Flag-Waving  Name_Calling,Labeling  \\\n",
       "0             4.921929  2.460964      0.00000               0.000000   \n",
       "1             0.000000  0.000000      1.87059               3.741179   \n",
       "2             0.000000  0.000000      0.00000               1.762583   \n",
       "3             0.000000  0.000000      0.00000               0.000000   \n",
       "4             2.290091  0.000000      0.00000               0.000000   \n",
       "\n",
       "   Exaggeration,Minimisation  Black-and-White_Fallacy  \\\n",
       "0                        0.0                  0.00000   \n",
       "1                        0.0                  1.87059   \n",
       "2                        0.0                  0.00000   \n",
       "3                        0.0                  0.00000   \n",
       "4                        0.0                  0.00000   \n",
       "\n",
       "   Bandwagon,Reductio_ad_hitlerum  Thought-terminating_Cliches  length  \\\n",
       "0                             0.0                          0.0     1.0   \n",
       "1                             0.0                          0.0     1.0   \n",
       "2                             0.0                          0.0     1.0   \n",
       "3                             0.0                          0.0     1.0   \n",
       "4                             0.0                          0.0     1.0   \n",
       "\n",
       "       count  \n",
       "0  19.687716  \n",
       "1  16.835307  \n",
       "2   9.694205  \n",
       "3   2.619338  \n",
       "4   9.160366  "
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_idf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiplicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    309.000000\n",
      "mean       6.929812\n",
      "std        4.568400\n",
      "min        0.410278\n",
      "25%        3.521560\n",
      "50%        5.965187\n",
      "75%        9.297641\n",
      "max       25.232400\n",
      "Name: Loaded_Language, dtype: float64\n",
      "\n",
      "\n",
      "count    77.000000\n",
      "mean      2.076194\n",
      "std       2.038275\n",
      "min       0.133347\n",
      "25%       0.881291\n",
      "50%       1.371974\n",
      "75%       2.576224\n",
      "max      11.391364\n",
      "Name: Slogans, dtype: float64\n",
      "\n",
      "\n",
      "count    70.000000\n",
      "mean      1.984891\n",
      "std       1.823956\n",
      "min       0.120892\n",
      "25%       0.792851\n",
      "50%       1.321003\n",
      "75%       2.383574\n",
      "max       9.865009\n",
      "Name: Whataboutism,Straw_Men,Red_Herring, dtype: float64\n",
      "\n",
      "\n",
      "count    155.000000\n",
      "mean       2.623486\n",
      "std        2.882743\n",
      "min        0.133347\n",
      "25%        0.964002\n",
      "50%        1.642991\n",
      "75%        3.073855\n",
      "max       16.471006\n",
      "Name: Appeal_to_fear-prejudice, dtype: float64\n",
      "\n",
      "\n",
      "count    103.000000\n",
      "mean       1.941928\n",
      "std        1.488283\n",
      "min        0.183488\n",
      "25%        0.941941\n",
      "50%        1.620720\n",
      "75%        2.491856\n",
      "max        9.946220\n",
      "Name: Causal_Oversimplification, dtype: float64\n",
      "\n",
      "\n",
      "count    160.000000\n",
      "mean       4.078299\n",
      "std        4.417322\n",
      "min        0.240809\n",
      "25%        1.198241\n",
      "50%        2.460437\n",
      "75%        5.182999\n",
      "max       28.120215\n",
      "Name: Repetition, dtype: float64\n",
      "\n",
      "\n",
      "count    83.000000\n",
      "mean      2.754568\n",
      "std       2.920362\n",
      "min       0.183488\n",
      "25%       0.907356\n",
      "50%       1.993044\n",
      "75%       3.157702\n",
      "max      15.961286\n",
      "Name: Appeal_to_Authority, dtype: float64\n",
      "\n",
      "\n",
      "count    160.000000\n",
      "mean       3.089156\n",
      "std        2.429551\n",
      "min        0.255565\n",
      "25%        1.205071\n",
      "50%        2.428676\n",
      "75%        4.237383\n",
      "max       10.997100\n",
      "Name: Doubt, dtype: float64\n",
      "\n",
      "\n",
      "count    127.000000\n",
      "mean       2.259834\n",
      "std        1.738027\n",
      "min        0.183488\n",
      "25%        1.171218\n",
      "50%        1.821172\n",
      "75%        2.782617\n",
      "max       12.204802\n",
      "Name: Flag-Waving, dtype: float64\n",
      "\n",
      "\n",
      "count    217.000000\n",
      "mean       4.533856\n",
      "std        4.330155\n",
      "min        0.133347\n",
      "25%        1.717483\n",
      "50%        3.022631\n",
      "75%        5.903479\n",
      "max       30.429317\n",
      "Name: Name_Calling,Labeling, dtype: float64\n",
      "\n",
      "\n",
      "count    182.000000\n",
      "mean       2.929663\n",
      "std        2.224720\n",
      "min        0.133347\n",
      "25%        1.416495\n",
      "50%        2.331781\n",
      "75%        3.660463\n",
      "max       14.225910\n",
      "Name: Exaggeration,Minimisation, dtype: float64\n",
      "\n",
      "\n",
      "count    68.000000\n",
      "mean      1.695110\n",
      "std       1.258013\n",
      "min       0.179287\n",
      "25%       0.871672\n",
      "50%       1.289568\n",
      "75%       2.346267\n",
      "max       6.793287\n",
      "Name: Black-and-White_Fallacy, dtype: float64\n",
      "\n",
      "\n",
      "count    49.000000\n",
      "mean      1.784813\n",
      "std       1.557059\n",
      "min       0.120892\n",
      "25%       0.777006\n",
      "50%       1.219760\n",
      "75%       2.320964\n",
      "max       6.952113\n",
      "Name: Bandwagon,Reductio_ad_hitlerum, dtype: float64\n",
      "\n",
      "\n",
      "count    67.000000\n",
      "mean      1.416937\n",
      "std       0.894961\n",
      "min       0.120892\n",
      "25%       0.714352\n",
      "50%       1.176259\n",
      "75%       2.038436\n",
      "max       4.010461\n",
      "Name: Thought-terminating_Cliches, dtype: float64\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X=list(set(labels))\n",
    "for L in X:\n",
    "    print(norm_idf[norm_idf[L]>0][L].describe(),end='\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    357.000000\n",
      "mean       5.998073\n",
      "std        4.864222\n",
      "min        0.000000\n",
      "25%        2.352037\n",
      "50%        5.320429\n",
      "75%        8.523222\n",
      "max       25.232400\n",
      "Name: Loaded_Language, dtype: float64\n",
      "\n",
      "\n",
      "count    357.000000\n",
      "mean       0.447807\n",
      "std        1.272077\n",
      "min        0.000000\n",
      "25%        0.000000\n",
      "50%        0.000000\n",
      "75%        0.000000\n",
      "max       11.391364\n",
      "Name: Slogans, dtype: float64\n",
      "\n",
      "\n",
      "count    357.000000\n",
      "mean       0.389194\n",
      "std        1.125871\n",
      "min        0.000000\n",
      "25%        0.000000\n",
      "50%        0.000000\n",
      "75%        0.000000\n",
      "max        9.865009\n",
      "Name: Whataboutism,Straw_Men,Red_Herring, dtype: float64\n",
      "\n",
      "\n",
      "count    357.000000\n",
      "mean       1.139049\n",
      "std        2.300100\n",
      "min        0.000000\n",
      "25%        0.000000\n",
      "50%        0.000000\n",
      "75%        1.340567\n",
      "max       16.471006\n",
      "Name: Appeal_to_fear-prejudice, dtype: float64\n",
      "\n",
      "\n",
      "count    357.000000\n",
      "mean       0.560276\n",
      "std        1.187818\n",
      "min        0.000000\n",
      "25%        0.000000\n",
      "50%        0.000000\n",
      "75%        0.755326\n",
      "max        9.946220\n",
      "Name: Causal_Oversimplification, dtype: float64\n",
      "\n",
      "\n",
      "count    357.000000\n",
      "mean       1.827809\n",
      "std        3.583291\n",
      "min        0.000000\n",
      "25%        0.000000\n",
      "50%        0.000000\n",
      "75%        2.139012\n",
      "max       28.120215\n",
      "Name: Repetition, dtype: float64\n",
      "\n",
      "\n",
      "count    357.000000\n",
      "mean       0.640418\n",
      "std        1.822684\n",
      "min        0.000000\n",
      "25%        0.000000\n",
      "50%        0.000000\n",
      "75%        0.000000\n",
      "max       15.961286\n",
      "Name: Appeal_to_Authority, dtype: float64\n",
      "\n",
      "\n",
      "count    357.000000\n",
      "mean       1.384496\n",
      "std        2.236750\n",
      "min        0.000000\n",
      "25%        0.000000\n",
      "50%        0.000000\n",
      "75%        2.228149\n",
      "max       10.997100\n",
      "Name: Doubt, dtype: float64\n",
      "\n",
      "\n",
      "count    357.000000\n",
      "mean       0.803919\n",
      "std        1.497619\n",
      "min        0.000000\n",
      "25%        0.000000\n",
      "50%        0.000000\n",
      "75%        1.220019\n",
      "max       12.204802\n",
      "Name: Flag-Waving, dtype: float64\n",
      "\n",
      "\n",
      "count    357.000000\n",
      "mean       2.755873\n",
      "std        4.036113\n",
      "min        0.000000\n",
      "25%        0.000000\n",
      "50%        1.298116\n",
      "75%        3.810737\n",
      "max       30.429317\n",
      "Name: Name_Calling,Labeling, dtype: float64\n",
      "\n",
      "\n",
      "count    357.000000\n",
      "mean       1.493554\n",
      "std        2.160400\n",
      "min        0.000000\n",
      "25%        0.000000\n",
      "50%        0.255565\n",
      "75%        2.347707\n",
      "max       14.225910\n",
      "Name: Exaggeration,Minimisation, dtype: float64\n",
      "\n",
      "\n",
      "count    357.000000\n",
      "mean       0.322878\n",
      "std        0.861485\n",
      "min        0.000000\n",
      "25%        0.000000\n",
      "50%        0.000000\n",
      "75%        0.000000\n",
      "max        6.793287\n",
      "Name: Black-and-White_Fallacy, dtype: float64\n",
      "\n",
      "\n",
      "count    357.000000\n",
      "mean       0.244974\n",
      "std        0.839744\n",
      "min        0.000000\n",
      "25%        0.000000\n",
      "50%        0.000000\n",
      "75%        0.000000\n",
      "max        6.952113\n",
      "Name: Bandwagon,Reductio_ad_hitlerum, dtype: float64\n",
      "\n",
      "\n",
      "count    357.000000\n",
      "mean       0.265924\n",
      "std        0.674858\n",
      "min        0.000000\n",
      "25%        0.000000\n",
      "50%        0.000000\n",
      "75%        0.000000\n",
      "max        4.010461\n",
      "Name: Thought-terminating_Cliches, dtype: float64\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for L in X:\n",
    "    print(norm_idf[L].describe(),end='\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Loaded_Language</th>\n",
       "      <th>Slogans</th>\n",
       "      <th>Whataboutism,Straw_Men,Red_Herring</th>\n",
       "      <th>Appeal_to_fear-prejudice</th>\n",
       "      <th>Causal_Oversimplification</th>\n",
       "      <th>Repetition</th>\n",
       "      <th>Appeal_to_Authority</th>\n",
       "      <th>Doubt</th>\n",
       "      <th>Flag-Waving</th>\n",
       "      <th>Name_Calling,Labeling</th>\n",
       "      <th>Exaggeration,Minimisation</th>\n",
       "      <th>Black-and-White_Fallacy</th>\n",
       "      <th>Bandwagon,Reductio_ad_hitlerum</th>\n",
       "      <th>Thought-terminating_Cliches</th>\n",
       "      <th>length</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>111111111</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2332</td>\n",
       "      <td>19.687716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>111111112</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3068</td>\n",
       "      <td>16.835307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>111111113</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6512</td>\n",
       "      <td>9.694205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>111111114</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2191</td>\n",
       "      <td>2.619338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>111111115</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2506</td>\n",
       "      <td>9.160366</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID  Loaded_Language  Slogans  Whataboutism,Straw_Men,Red_Herring  \\\n",
       "0  111111111                0        0                                   0   \n",
       "1  111111112                3        2                                   0   \n",
       "2  111111113                4        1                                   1   \n",
       "3  111111114                0        0                                   0   \n",
       "4  111111115                3        0                                   0   \n",
       "\n",
       "   Appeal_to_fear-prejudice  Causal_Oversimplification  Repetition  \\\n",
       "0                         4                          0           1   \n",
       "1                         0                          0           0   \n",
       "2                         0                          3           0   \n",
       "3                         1                          0           0   \n",
       "4                         0                          0           0   \n",
       "\n",
       "   Appeal_to_Authority  Doubt  Flag-Waving  Name_Calling,Labeling  \\\n",
       "0                    2      1            0                      0   \n",
       "1                    0      0            1                      2   \n",
       "2                    0      0            0                      2   \n",
       "3                    0      0            0                      0   \n",
       "4                    1      0            0                      0   \n",
       "\n",
       "   Exaggeration,Minimisation  Black-and-White_Fallacy  \\\n",
       "0                          0                        0   \n",
       "1                          0                        1   \n",
       "2                          0                        0   \n",
       "3                          0                        0   \n",
       "4                          0                        0   \n",
       "\n",
       "   Bandwagon,Reductio_ad_hitlerum  Thought-terminating_Cliches  length  \\\n",
       "0                               0                            0    2332   \n",
       "1                               0                            0    3068   \n",
       "2                               0                            0    6512   \n",
       "3                               0                            0    2191   \n",
       "4                               0                            0    2506   \n",
       "\n",
       "       count  \n",
       "0  19.687716  \n",
       "1  16.835307  \n",
       "2   9.694205  \n",
       "3   2.619338  \n",
       "4   9.160366  "
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_x,_y=idf[X[0]],idf[X[12]]\n",
    "plt.scatter(_x,_y)\n",
    "plt.show()\n",
    "print(pearsonr(_x,_y))\n",
    "print(spearmanr(_x,_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.relplot(y=X[2], x=idf.index, hue=X[11], data=idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=b_idf.drop(['ID','length'],axis=1)\n",
    "sns.set_style(\"dark\")\n",
    "def correlation_heatmap(train):\n",
    "    correlations = train.corr('spearman')\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10,10))\n",
    "    sns.heatmap(correlations, center=0.0, fmt='.2f',\n",
    "                square=True, linewidths=.5, annot=True, cbar_kws={\"shrink\": .70})\n",
    "    plt.show();\n",
    "    \n",
    "correlation_heatmap(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlations = train.corr()\n",
    "correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,14):\n",
    "    q=((b_idf[X[0]]&b_idf[X[i]]).mean(),)\n",
    "    print(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_idf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(b_idf[X[0]]&b_idf[X[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    309.000000\n",
      "mean      19.540734\n",
      "std       12.173004\n",
      "min        0.951105\n",
      "50%       16.576350\n",
      "80%       29.489613\n",
      "max       67.573072\n",
      "Name: count, dtype: float64\n",
      "count    48.000000\n",
      "mean     10.121207\n",
      "std       8.084756\n",
      "min       1.248688\n",
      "50%       7.617709\n",
      "80%      16.983031\n",
      "max      33.313278\n",
      "Name: count, dtype: float64\n",
      "count    77.000000\n",
      "mean     23.639513\n",
      "std      11.930715\n",
      "min       5.733902\n",
      "50%      21.862740\n",
      "80%      32.969285\n",
      "max      63.901566\n",
      "Name: count, dtype: float64\n",
      "count    280.000000\n",
      "mean      16.798794\n",
      "std       11.785776\n",
      "min        0.951105\n",
      "50%       14.160704\n",
      "80%       24.241362\n",
      "max       67.573072\n",
      "Name: count, dtype: float64\n",
      "count    70.000000\n",
      "mean     23.869497\n",
      "std      13.293343\n",
      "min       6.039431\n",
      "50%      21.859883\n",
      "80%      33.009615\n",
      "max      67.573072\n",
      "Name: count, dtype: float64\n",
      "count    287.000000\n",
      "mean      16.909547\n",
      "std       11.447546\n",
      "min        0.951105\n",
      "50%       14.279272\n",
      "80%       24.955937\n",
      "max       59.092960\n",
      "Name: count, dtype: float64\n",
      "count    155.000000\n",
      "mean      21.157534\n",
      "std       12.551873\n",
      "min        1.641112\n",
      "50%       19.687716\n",
      "80%       30.382387\n",
      "max       67.573072\n",
      "Name: count, dtype: float64\n",
      "count    202.000000\n",
      "mean      16.061817\n",
      "std       11.342360\n",
      "min        0.951105\n",
      "50%       13.848956\n",
      "80%       22.953530\n",
      "max       63.901566\n",
      "Name: count, dtype: float64\n",
      "count    103.000000\n",
      "mean      24.117901\n",
      "std       13.033169\n",
      "min        2.585121\n",
      "50%       20.108512\n",
      "80%       36.398072\n",
      "max       67.573072\n",
      "Name: count, dtype: float64\n",
      "count    254.000000\n",
      "mean      15.904571\n",
      "std       10.912656\n",
      "min        0.951105\n",
      "50%       13.431310\n",
      "80%       24.814893\n",
      "max       63.901566\n",
      "Name: count, dtype: float64\n",
      "count    160.000000\n",
      "mean      22.878512\n",
      "std       12.977102\n",
      "min        1.248688\n",
      "50%       19.795825\n",
      "80%       32.214067\n",
      "max       67.573072\n",
      "Name: count, dtype: float64\n",
      "count    197.000000\n",
      "mean      14.534735\n",
      "std        9.968135\n",
      "min        0.951105\n",
      "50%       12.960103\n",
      "80%       21.089555\n",
      "max       63.901566\n",
      "Name: count, dtype: float64\n",
      "count    83.000000\n",
      "mean     22.568830\n",
      "std      13.405513\n",
      "min       2.827078\n",
      "50%      19.687716\n",
      "80%      32.561744\n",
      "max      67.573072\n",
      "Name: count, dtype: float64\n",
      "count    274.000000\n",
      "mean      16.973328\n",
      "std       11.430290\n",
      "min        0.951105\n",
      "50%       14.708849\n",
      "80%       25.317568\n",
      "max       63.901566\n",
      "Name: count, dtype: float64\n",
      "count    160.000000\n",
      "mean      20.622524\n",
      "std       11.626227\n",
      "min        1.641112\n",
      "50%       18.008590\n",
      "80%       30.382387\n",
      "max       67.573072\n",
      "Name: count, dtype: float64\n",
      "count    197.000000\n",
      "mean      16.367010\n",
      "std       12.228194\n",
      "min        0.951105\n",
      "50%       13.435714\n",
      "80%       24.573407\n",
      "max       63.901566\n",
      "Name: count, dtype: float64\n",
      "count    127.000000\n",
      "mean      20.607701\n",
      "std       11.783188\n",
      "min        2.585121\n",
      "50%       18.197286\n",
      "80%       29.510835\n",
      "max       51.807817\n",
      "Name: count, dtype: float64\n",
      "count    230.000000\n",
      "mean      16.985768\n",
      "std       12.154534\n",
      "min        0.951105\n",
      "50%       14.240856\n",
      "80%       27.344230\n",
      "max       67.573072\n",
      "Name: count, dtype: float64\n",
      "count    217.000000\n",
      "mean      22.358999\n",
      "std       12.043229\n",
      "min        2.048900\n",
      "50%       19.798083\n",
      "80%       31.143926\n",
      "max       67.573072\n",
      "Name: count, dtype: float64\n",
      "count    140.000000\n",
      "mean      11.942871\n",
      "std        9.228182\n",
      "min        0.951105\n",
      "50%        9.658185\n",
      "80%       16.925845\n",
      "max       57.398950\n",
      "Name: count, dtype: float64\n",
      "count    182.000000\n",
      "mean      23.478945\n",
      "std       12.595831\n",
      "min        2.306660\n",
      "50%       21.459914\n",
      "80%       32.484505\n",
      "max       67.573072\n",
      "Name: count, dtype: float64\n",
      "count    175.000000\n",
      "mean      12.861353\n",
      "std        8.848762\n",
      "min        0.951105\n",
      "50%       11.524035\n",
      "80%       18.565639\n",
      "max       43.524143\n",
      "Name: count, dtype: float64\n",
      "count    68.000000\n",
      "mean     21.369207\n",
      "std      11.190457\n",
      "min       4.446056\n",
      "50%      18.893940\n",
      "80%      29.708606\n",
      "max      59.092960\n",
      "Name: count, dtype: float64\n",
      "count    289.000000\n",
      "mean      17.546016\n",
      "std       12.247966\n",
      "min        0.951105\n",
      "50%       14.311644\n",
      "80%       26.542203\n",
      "max       67.573072\n",
      "Name: count, dtype: float64\n",
      "count    49.000000\n",
      "mean     23.534374\n",
      "std      12.638209\n",
      "min       7.258393\n",
      "50%      18.831728\n",
      "80%      31.704037\n",
      "max      63.901566\n",
      "Name: count, dtype: float64\n",
      "count    308.000000\n",
      "mean      17.437404\n",
      "std       11.856936\n",
      "min        0.951105\n",
      "50%       14.708849\n",
      "80%       26.133891\n",
      "max       67.573072\n",
      "Name: count, dtype: float64\n",
      "count    67.000000\n",
      "mean     20.943756\n",
      "std      11.912033\n",
      "min       1.641112\n",
      "50%      18.366430\n",
      "80%      30.907223\n",
      "max      67.573072\n",
      "Name: count, dtype: float64\n",
      "count    290.000000\n",
      "mean      17.657493\n",
      "std       12.119001\n",
      "min        0.951105\n",
      "50%       15.109850\n",
      "80%       27.253908\n",
      "max       63.901566\n",
      "Name: count, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "for n in range(14):\n",
    "    print(idf[idf[X[n]]!=0]['count'].describe([0.8]))\n",
    "    print(idf[idf[X[n]]==0]['count'].describe([0.8]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getWordSpans(text):\n",
    "    wordlist=[]\n",
    "    def trans(text,pointer=0):\n",
    "        if pointer==len(text)-1:\n",
    "            return True\n",
    "        else:\n",
    "            while(not text[pointer].isalpha() and pointer<len(text)-1):\n",
    "                pointer=pointer+1\n",
    "            s=pointer\n",
    "            while(text[pointer].isalpha() and pointer<len(text)-1):\n",
    "                pointer=pointer+1\n",
    "            wordlist.append([s,pointer])\n",
    "            return trans(text,pointer)\n",
    "    try:\n",
    "        trans(text)\n",
    "    except :\n",
    "        return -1\n",
    "    if(wordlist[-1][1]==wordlist[-1][0]):\n",
    "        wordlist=wordlist[:-1]\n",
    "    if(text[-1].isalpha()):\n",
    "        wordlist[-1][1]+=1\n",
    "    return wordlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 6],\n",
       " [7, 10],\n",
       " [11, 21],\n",
       " [22, 26],\n",
       " [27, 29],\n",
       " [30, 34],\n",
       " [35, 40],\n",
       " [41, 45],\n",
       " [46, 52],\n",
       " [53, 61],\n",
       " [62, 66],\n",
       " [67, 73],\n",
       " [75, 84],\n",
       " [87, 93],\n",
       " [94, 106],\n",
       " [107, 115],\n",
       " [116, 124],\n",
       " [125, 128],\n",
       " [129, 139],\n",
       " [140, 144],\n",
       " [145, 147],\n",
       " [148, 151],\n",
       " [152, 156],\n",
       " [157, 162],\n",
       " [163, 164],\n",
       " [165, 168],\n",
       " [169, 176],\n",
       " [177, 181],\n",
       " [182, 185],\n",
       " [186, 192],\n",
       " [193, 201],\n",
       " [202, 206],\n",
       " [207, 210],\n",
       " [211, 218],\n",
       " [220, 223],\n",
       " [224, 226],\n",
       " [227, 234],\n",
       " [235, 239],\n",
       " [240, 244],\n",
       " [245, 249],\n",
       " [251, 257],\n",
       " [258, 265],\n",
       " [266, 270],\n",
       " [271, 274],\n",
       " [275, 283],\n",
       " [284, 290],\n",
       " [291, 293],\n",
       " [294, 305],\n",
       " [306, 310],\n",
       " [312, 323],\n",
       " [324, 332],\n",
       " [333, 337],\n",
       " [338, 345],\n",
       " [351, 354],\n",
       " [355, 362],\n",
       " [363, 370],\n",
       " [376, 380],\n",
       " [381, 387],\n",
       " [388, 395],\n",
       " [396, 401],\n",
       " [402, 406],\n",
       " [407, 415],\n",
       " [416, 418],\n",
       " [419, 423],\n",
       " [424, 432],\n",
       " [433, 438],\n",
       " [439, 445],\n",
       " [446, 451],\n",
       " [452, 462],\n",
       " [463, 465],\n",
       " [466, 467],\n",
       " [472, 476],\n",
       " [477, 479],\n",
       " [480, 484],\n",
       " [486, 489],\n",
       " [490, 497],\n",
       " [502, 506],\n",
       " [507, 510],\n",
       " [511, 518],\n",
       " [519, 524],\n",
       " [526, 529],\n",
       " [530, 534],\n",
       " [535, 538],\n",
       " [539, 546],\n",
       " [547, 549],\n",
       " [550, 553],\n",
       " [554, 562],\n",
       " [563, 566],\n",
       " [567, 572],\n",
       " [573, 575],\n",
       " [576, 580],\n",
       " [581, 586],\n",
       " [587, 597],\n",
       " [598, 604],\n",
       " [605, 612],\n",
       " [613, 619],\n",
       " [620, 622],\n",
       " [623, 631],\n",
       " [632, 641],\n",
       " [642, 650],\n",
       " [652, 665],\n",
       " [666, 667],\n",
       " [668, 674],\n",
       " [675, 677],\n",
       " [682, 687],\n",
       " [688, 696],\n",
       " [697, 699],\n",
       " [700, 703],\n",
       " [704, 708],\n",
       " [709, 711],\n",
       " [712, 723],\n",
       " [724, 731],\n",
       " [732, 736],\n",
       " [737, 744],\n",
       " [745, 750],\n",
       " [751, 755],\n",
       " [756, 764],\n",
       " [765, 773],\n",
       " [774, 776],\n",
       " [777, 778],\n",
       " [779, 786],\n",
       " [787, 789],\n",
       " [790, 794],\n",
       " [795, 801],\n",
       " [803, 808],\n",
       " [809, 814],\n",
       " [815, 820],\n",
       " [821, 825],\n",
       " [826, 829],\n",
       " [830, 834],\n",
       " [836, 843],\n",
       " [845, 848],\n",
       " [849, 850],\n",
       " [851, 856],\n",
       " [857, 865],\n",
       " [867, 870],\n",
       " [871, 877],\n",
       " [878, 882],\n",
       " [883, 885],\n",
       " [886, 890],\n",
       " [891, 896],\n",
       " [898, 903],\n",
       " [904, 911],\n",
       " [912, 915],\n",
       " [916, 924],\n",
       " [925, 927],\n",
       " [928, 936],\n",
       " [937, 945],\n",
       " [946, 950],\n",
       " [951, 956],\n",
       " [957, 964],\n",
       " [966, 970],\n",
       " [971, 973],\n",
       " [974, 979],\n",
       " [980, 983],\n",
       " [984, 987],\n",
       " [988, 995],\n",
       " [996, 998],\n",
       " [1000, 1004],\n",
       " [1005, 1007],\n",
       " [1008, 1011],\n",
       " [1012, 1016],\n",
       " [1017, 1028],\n",
       " [1029, 1033],\n",
       " [1034, 1045],\n",
       " [1046, 1052],\n",
       " [1053, 1058],\n",
       " [1059, 1062],\n",
       " [1063, 1072],\n",
       " [1073, 1077],\n",
       " [1078, 1080],\n",
       " [1081, 1082],\n",
       " [1083, 1087],\n",
       " [1088, 1098],\n",
       " [1099, 1107],\n",
       " [1108, 1112],\n",
       " [1113, 1120],\n",
       " [1121, 1124],\n",
       " [1125, 1132],\n",
       " [1133, 1137],\n",
       " [1138, 1142],\n",
       " [1143, 1154],\n",
       " [1155, 1159],\n",
       " [1160, 1168],\n",
       " [1170, 1175],\n",
       " [1176, 1179],\n",
       " [1180, 1187],\n",
       " [1188, 1192],\n",
       " [1193, 1195],\n",
       " [1196, 1200],\n",
       " [1201, 1203],\n",
       " [1204, 1208],\n",
       " [1210, 1211],\n",
       " [1212, 1222],\n",
       " [1223, 1229],\n",
       " [1230, 1233],\n",
       " [1234, 1240],\n",
       " [1241, 1245],\n",
       " [1246, 1249],\n",
       " [1250, 1257],\n",
       " [1258, 1259],\n",
       " [1260, 1265],\n",
       " [1266, 1269],\n",
       " [1270, 1273],\n",
       " [1274, 1280],\n",
       " [1281, 1284],\n",
       " [1285, 1290],\n",
       " [1291, 1293],\n",
       " [1294, 1299],\n",
       " [1300, 1306],\n",
       " [1310, 1313],\n",
       " [1314, 1315],\n",
       " [1316, 1319],\n",
       " [1320, 1322],\n",
       " [1323, 1325],\n",
       " [1329, 1337],\n",
       " [1338, 1342],\n",
       " [1343, 1347],\n",
       " [1348, 1352],\n",
       " [1353, 1355],\n",
       " [1356, 1359],\n",
       " [1360, 1364],\n",
       " [1366, 1368],\n",
       " [1375, 1376],\n",
       " [1377, 1378],\n",
       " [1381, 1383],\n",
       " [1384, 1391],\n",
       " [1392, 1397],\n",
       " [1398, 1399],\n",
       " [1400, 1410],\n",
       " [1411, 1415],\n",
       " [1416, 1418],\n",
       " [1419, 1420],\n",
       " [1423, 1426],\n",
       " [1427, 1432],\n",
       " [1433, 1438],\n",
       " [1439, 1442],\n",
       " [1446, 1454],\n",
       " [1455, 1457],\n",
       " [1458, 1459],\n",
       " [1460, 1464],\n",
       " [1465, 1470],\n",
       " [1472, 1474],\n",
       " [1481, 1482],\n",
       " [1483, 1484],\n",
       " [1487, 1492],\n",
       " [1493, 1494],\n",
       " [1495, 1505],\n",
       " [1506, 1515],\n",
       " [1516, 1523],\n",
       " [1524, 1527],\n",
       " [1528, 1532],\n",
       " [1533, 1537],\n",
       " [1539, 1540],\n",
       " [1541, 1544],\n",
       " [1545, 1546],\n",
       " [1547, 1552],\n",
       " [1553, 1558],\n",
       " [1559, 1561],\n",
       " [1562, 1567],\n",
       " [1568, 1575],\n",
       " [1579, 1581],\n",
       " [1582, 1586],\n",
       " [1587, 1592],\n",
       " [1593, 1598],\n",
       " [1602, 1606],\n",
       " [1607, 1614],\n",
       " [1615, 1620],\n",
       " [1622, 1629],\n",
       " [1631, 1641],\n",
       " [1642, 1643],\n",
       " [1644, 1650],\n",
       " [1651, 1658],\n",
       " [1660, 1664],\n",
       " [1665, 1666],\n",
       " [1667, 1677],\n",
       " [1681, 1683],\n",
       " [1684, 1688],\n",
       " [1689, 1692],\n",
       " [1693, 1701],\n",
       " [1702, 1706],\n",
       " [1708, 1713],\n",
       " [1714, 1716],\n",
       " [1717, 1722],\n",
       " [1724, 1727],\n",
       " [1728, 1730],\n",
       " [1731, 1739],\n",
       " [1743, 1756],\n",
       " [1757, 1767],\n",
       " [1768, 1773]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getWordSpans(open('datasets/dev-articles/article730081389.txt','r').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "550 0\n",
      "754 1\n",
      "335 2\n",
      "438 3\n",
      "478 4\n",
      "443 5\n",
      "433 6\n",
      "901 7\n",
      "420 8\n",
      "239 9\n",
      "910 10\n",
      "649 11\n",
      "901 12\n",
      "542 13\n",
      "672 14\n",
      "1244 15\n",
      "412 16\n",
      "938 17\n",
      "466 18\n",
      "753 19\n",
      "432 20\n",
      "917 21\n",
      "1291 22\n",
      "598 23\n",
      "501 24\n",
      "960 25\n",
      "635 26\n",
      "321 27\n",
      "515 28\n",
      "443 29\n",
      "795 30\n",
      "701 31\n",
      "433 32\n",
      "497 33\n",
      "116 34\n",
      "172 35\n",
      "285 36\n",
      "704 37\n",
      "719 38\n",
      "357 39\n",
      "469 40\n",
      "2259 41\n",
      "825 42\n",
      "590 43\n",
      "3830 44\n",
      "360 45\n",
      "594 46\n",
      "551 47\n",
      "2067 48\n",
      "694 49\n",
      "378 50\n",
      "660 51\n",
      "1065 52\n",
      "7288 53\n",
      "296 54\n",
      "364 55\n",
      "390 56\n",
      "1029 57\n",
      "1174 58\n",
      "388 59\n",
      "394 60\n",
      "715 61\n",
      "485 62\n",
      "644 63\n",
      "507 64\n",
      "550 65\n",
      "908 66\n",
      "1305 67\n",
      "240 68\n",
      "613 69\n",
      "831 70\n",
      "969 71\n",
      "505 72\n",
      "205 73\n",
      "167 74\n",
      "340 75\n",
      "582 76\n",
      "685 77\n",
      "2177 78\n",
      "421 79\n",
      "523 80\n",
      "111 81\n",
      "184 82\n",
      "916 83\n",
      "2465 84\n",
      "238 85\n",
      "1883 86\n",
      "1966 87\n",
      "433 88\n",
      "5208 89\n",
      "979 90\n",
      "826 91\n",
      "394 92\n",
      "3180 93\n",
      "1337 94\n",
      "638 95\n",
      "905 96\n",
      "572 97\n",
      "733 98\n",
      "364 99\n",
      "925 100\n",
      "1511 101\n",
      "1040 102\n",
      "456 103\n",
      "696 104\n",
      "396 105\n",
      "1739 106\n",
      "420 107\n",
      "1040 108\n",
      "3065 109\n",
      "380 110\n",
      "903 111\n",
      "1379 112\n",
      "441 113\n",
      "1320 114\n",
      "1429 115\n",
      "884 116\n",
      "374 117\n",
      "447 118\n",
      "678 119\n",
      "566 120\n",
      "727 121\n",
      "904 122\n",
      "330 123\n",
      "784 124\n",
      "696 125\n",
      "293 126\n",
      "2516 127\n",
      "1053 128\n",
      "339 129\n",
      "1048 130\n",
      "672 131\n",
      "811 132\n",
      "2035 133\n",
      "985 134\n",
      "521 135\n",
      "1073 136\n",
      "3519 137\n",
      "587 138\n",
      "2463 139\n",
      "2188 140\n",
      "696 141\n",
      "576 142\n",
      "2205 143\n",
      "775 144\n",
      "316 145\n",
      "1188 146\n",
      "1509 147\n",
      "626 148\n",
      "603 149\n",
      "5601 150\n",
      "838 151\n",
      "872 152\n",
      "695 153\n",
      "146 154\n",
      "818 155\n",
      "370 156\n",
      "2310 157\n",
      "538 158\n",
      "408 159\n",
      "955 160\n",
      "934 161\n",
      "475 162\n",
      "829 163\n",
      "3902 164\n",
      "1400 165\n",
      "473 166\n",
      "870 167\n",
      "360 168\n",
      "759 169\n",
      "4113 170\n",
      "422 171\n",
      "889 172\n",
      "365 173\n",
      "1454 174\n",
      "981 175\n",
      "344 176\n",
      "344 177\n",
      "4639 178\n",
      "419 179\n",
      "1589 180\n",
      "972 181\n",
      "2208 182\n",
      "797 183\n",
      "495 184\n",
      "200 185\n",
      "782 186\n",
      "239 187\n",
      "457 188\n",
      "1116 189\n",
      "849 190\n",
      "341 191\n",
      "994 192\n",
      "1027 193\n",
      "299 194\n",
      "460 195\n",
      "391 196\n",
      "395 197\n",
      "841 198\n",
      "1767 199\n",
      "417 200\n",
      "522 201\n",
      "217 202\n",
      "1488 203\n",
      "958 204\n",
      "1122 205\n",
      "271 206\n",
      "473 207\n",
      "458 208\n",
      "515 209\n",
      "459 210\n",
      "625 211\n",
      "568 212\n",
      "1429 213\n",
      "402 214\n",
      "537 215\n",
      "772 216\n",
      "375 217\n",
      "624 218\n",
      "502 219\n",
      "548 220\n",
      "2178 221\n",
      "144 222\n",
      "1187 223\n",
      "1053 224\n",
      "807 225\n",
      "723 226\n",
      "1100 227\n",
      "735 228\n",
      "762 229\n",
      "745 230\n",
      "820 231\n",
      "1148 232\n",
      "1607 233\n",
      "912 234\n",
      "532 235\n",
      "1185 236\n",
      "331 237\n",
      "1057 238\n",
      "3220 239\n",
      "475 240\n",
      "352 241\n",
      "2954 242\n",
      "623 243\n",
      "332 244\n",
      "853 245\n",
      "1180 246\n",
      "1618 247\n",
      "840 248\n",
      "427 249\n",
      "494 250\n",
      "876 251\n",
      "476 252\n",
      "449 253\n",
      "1527 254\n",
      "7714 255\n",
      "843 256\n",
      "614 257\n",
      "1088 258\n",
      "586 259\n",
      "127 260\n",
      "1616 261\n",
      "543 262\n",
      "339 263\n",
      "481 264\n",
      "681 265\n",
      "510 266\n",
      "502 267\n",
      "2434 268\n",
      "759 269\n",
      "1755 270\n",
      "911 271\n",
      "477 272\n",
      "1204 273\n",
      "738 274\n",
      "1272 275\n",
      "924 276\n",
      "688 277\n",
      "1043 278\n",
      "1143 279\n",
      "1962 280\n",
      "457 281\n",
      "386 282\n",
      "1781 283\n",
      "1997 284\n",
      "298 285\n",
      "414 286\n",
      "149 287\n",
      "656 288\n",
      "1373 289\n",
      "694 290\n",
      "2200 291\n",
      "791 292\n",
      "1842 293\n",
      "514 294\n",
      "760 295\n",
      "387 296\n",
      "426 297\n",
      "403 298\n",
      "885 299\n",
      "2008 300\n",
      "509 301\n",
      "727 302\n",
      "554 303\n",
      "629 304\n",
      "273 305\n",
      "548 306\n",
      "643 307\n",
      "669 308\n",
      "2576 309\n",
      "514 310\n",
      "1293 311\n",
      "1039 312\n",
      "489 313\n",
      "1114 314\n",
      "832 315\n",
      "1209 316\n",
      "151 317\n",
      "765 318\n",
      "668 319\n",
      "654 320\n",
      "431 321\n",
      "539 322\n",
      "1451 323\n",
      "493 324\n",
      "1213 325\n",
      "960 326\n",
      "500 327\n",
      "684 328\n",
      "3398 329\n",
      "695 330\n",
      "1303 331\n",
      "748 332\n",
      "517 333\n",
      "236 334\n",
      "699 335\n",
      "318 336\n",
      "191 337\n",
      "382 338\n",
      "387 339\n",
      "1034 340\n",
      "1191 341\n",
      "799 342\n",
      "394 343\n",
      "767 344\n",
      "1757 345\n",
      "793 346\n",
      "239 347\n",
      "1320 348\n",
      "952 349\n",
      "985 350\n",
      "1228 351\n",
      "552 352\n",
      "1282 353\n",
      "637 354\n",
      "310 355\n",
      "366 356\n",
      "700 357\n",
      "324 358\n",
      "173 359\n",
      "657 360\n",
      "796 361\n",
      "593 362\n",
      "509 363\n",
      "1779 364\n",
      "2095 365\n",
      "676 366\n",
      "181 367\n",
      "400 368\n",
      "801 369\n",
      "3802 370\n"
     ]
    }
   ],
   "source": [
    "c=0\n",
    "for i in os.listdir('datasets/train-articles'):\n",
    "    print(len(getWordSpans(open('datasets/train-articles/'+i,'r').read())),c)\n",
    "    c=c+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.setrecursionlimit(10**4) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_folder = \"datasets/train-articles\" # check that the path to the datasets folder is correct, \n",
    "dev_folder = \"datasets/dev-articles\"     # if not adjust these variables accordingly\n",
    "train_labels_file = \"datasets/train-task2-TC.labels\"\n",
    "dev_template_labels_file = \"datasets/dev-task-TC-template.out\"\n",
    "task_TC_output_file = \"baseline-output-TC.txt\"\n",
    "\n",
    "def read_articles_from_file_list(folder_name, file_pattern=\"*.txt\"):\n",
    "    \"\"\"\n",
    "    Read articles from files matching patterns <file_pattern> from  \n",
    "    the directory <folder_name>. \n",
    "    The content of the article is saved in the dictionary whose key\n",
    "    is the id of the article (extracted from the file name).\n",
    "    Each element of <sentence_list> is one line of the article.\n",
    "    \"\"\"\n",
    "    file_list = glob.glob(os.path.join(folder_name, file_pattern))\n",
    "    articles = {}\n",
    "    article_id_list, sentence_id_list, sentence_list = ([], [], [])\n",
    "    for filename in sorted(file_list):\n",
    "        article_id = os.path.basename(filename).split(\".\")[0][7:]\n",
    "        with codecs.open(filename, \"r\", encoding=\"utf8\") as f:\n",
    "            articles[article_id] = f.read()\n",
    "    return articles\n",
    "\n",
    "\n",
    "def read_predictions_from_file(filename):\n",
    "    \"\"\"\n",
    "    Reader for the gold file and the template output file. \n",
    "    Return values are four arrays with article ids, labels \n",
    "    (or ? in the case of a template file), begin of a fragment, \n",
    "    end of a fragment. \n",
    "    \"\"\"\n",
    "    articles_id, span_starts, span_ends, gold_labels = ([], [], [], [])\n",
    "    with open(filename, \"r\") as f:\n",
    "        for row in f.readlines():\n",
    "            article_id, gold_label, span_start, span_end = row.rstrip().split(\"\\t\")\n",
    "            articles_id.append(article_id)\n",
    "            gold_labels.append(gold_label)\n",
    "            span_starts.append(span_start)\n",
    "            span_ends.append(span_end)\n",
    "    return articles_id, span_starts, span_ends, gold_labels\n",
    "\n",
    "\n",
    "def compute_features(articles, span_starts, span_ends):\n",
    "    # only one feature, the length of the span\n",
    "    return np.array([ int(sp_ends)-int(sp_starts) for sp_starts, sp_ends in zip(span_starts, span_ends) ]).reshape(-1, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "### MAIN ###\n",
    "\n",
    "# loading articles' content from *.txt files in the train folder\n",
    "articles = read_articles_from_file_list(train_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 6369 annotations from 357 articles\n"
     ]
    }
   ],
   "source": [
    "# loading gold labels, articles ids and sentence ids from files *.task-TC.labels in the train labels folder \n",
    "ref_articles_id, ref_span_starts, ref_span_ends, train_gold_labels = read_predictions_from_file(train_labels_file)\n",
    "print(\"Loaded %d annotations from %d articles\" % (len(ref_span_starts), len(set(ref_articles_id))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute one feature for each fragment, i.e. the length of the fragment, and train the model\n",
    "train = compute_features(articles, ref_span_starts, ref_span_ends)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/somesh/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions written to file baseline-output-TC.txt\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(penalty='l2', class_weight='balanced', solver=\"lbfgs\")\n",
    "model.fit(train, train_gold_labels)\n",
    "\n",
    "# reading data from the development set\n",
    "dev_articles = read_articles_from_file_list(dev_folder)\n",
    "dev_article_ids, dev_span_starts, dev_span_ends, dev_labels = read_predictions_from_file(dev_template_labels_file)\n",
    "\n",
    "# computing the predictions on the development set\n",
    "dev = compute_features(dev_articles, dev_span_starts, dev_span_ends)\n",
    "predictions = model.predict(dev)\n",
    "\n",
    "# writing predictions to file\n",
    "with open(task_TC_output_file, \"w\") as fout:\n",
    "    for article_id, prediction, span_start, span_end in zip(dev_article_ids, predictions, dev_span_starts, dev_span_ends):\n",
    "        fout.write(\"%s\\t%s\\t%s\\t%s\\n\" % (article_id, prediction, span_start, span_end))\n",
    "print(\"Predictions written to file \" + task_TC_output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
