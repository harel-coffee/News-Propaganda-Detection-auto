{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os.path\n",
    "import numpy as np\n",
    "import sys\n",
    "import codecs\n",
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.naive_bayes import MultinomialNB, ComplementNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATA LOAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_folder = \"datasets/train-articles\" # check that the path to the datasets folder is correct, \n",
    "dev_folder = \"datasets/dev-articles\"     # if not adjust these variables accordingly\n",
    "train_labels_file = \"datasets/train-task2-TC.labels\"\n",
    "dev_template_labels_file = \"datasets/dev-task-TC-template.out\"\n",
    "task_TC_output_file = \"output-TC.txt\"\n",
    "\n",
    "def read_articles_from_file_list(folder_name, file_pattern=\"*.txt\"):\n",
    "    \"\"\"\n",
    "    Read articles from files matching patterns <file_pattern> from  \n",
    "    the directory <folder_name>. \n",
    "    The content of the article is saved in the dictionary whose key\n",
    "    is the id of the article (extracted from the file name).\n",
    "    Each element of <sentence_list> is one line of the article.\n",
    "    \"\"\"\n",
    "    file_list = glob.glob(os.path.join(folder_name, file_pattern))\n",
    "    articles = {}\n",
    "    article_id_list, sentence_id_list, sentence_list = ([], [], [])\n",
    "    for filename in sorted(file_list):\n",
    "        article_id = os.path.basename(filename).split(\".\")[0][7:]\n",
    "        with codecs.open(filename, \"r\", encoding=\"utf8\") as f:\n",
    "            articles[article_id] = f.read()\n",
    "    return articles\n",
    "\n",
    "\n",
    "def read_predictions_from_file(filename):\n",
    "    \"\"\"\n",
    "    Reader for the gold file and the template output file. \n",
    "    Return values are four arrays with article ids, labels \n",
    "    (or ? in the case of a template file), begin of a fragment, \n",
    "    end of a fragment. \n",
    "    \"\"\"\n",
    "    articles_id, span_starts, span_ends, gold_labels = ([], [], [], [])\n",
    "    with open(filename, \"r\") as f:\n",
    "        for row in f.readlines():\n",
    "            article_id, gold_label, span_start, span_end = row.rstrip().split(\"\\t\")\n",
    "            articles_id.append(article_id)\n",
    "            gold_labels.append(gold_label)\n",
    "            span_starts.append(span_start)\n",
    "            span_ends.append(span_end)\n",
    "    return articles_id, span_starts, span_ends, gold_labels\n",
    "\n",
    "def compute_features_b(articles, span_starts, span_ends):\n",
    "    # only one feature, the length of the span\n",
    "    return np.array([ int(sp_ends)-int(sp_starts) for sp_starts, sp_ends in zip(span_starts, span_ends) ]).reshape(-1, 1)\n",
    "\n",
    "def clean(text):\n",
    "    text=text.lower()\n",
    "    text = re.sub(r'^https?:\\/\\/.*[\\r\\n]*', '', text, flags=re.MULTILINE)\n",
    "    text=re.sub('[“\"”]',' \" ',text)\n",
    "    retain='[^abcdefghijklmnopqrstuvwxyz!#?\". ]'\n",
    "    text=re.sub('[()–-]',' ',text)\n",
    "    text=re.sub(retain,'',text)\n",
    "    text=re.sub('[.]',' . ',text)\n",
    "    text=text.replace('?',' ? ')\n",
    "    text=text.replace('#',' # ')\n",
    "    text=text.replace('!',' ! ')\n",
    "    return ' '.join(text.split())\n",
    "\n",
    "# loading articles' content from *.txt files in the train folder\n",
    "articles = read_articles_from_file_list(train_folder)\n",
    "dev_articles = read_articles_from_file_list(dev_folder)\n",
    "\n",
    "def read_span(id,span,dev=False):\n",
    "    if dev:\n",
    "        return dev_articles[id][span[0]:span[1]]\n",
    "    else:\n",
    "        return articles[id][span[0]:span[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 6129 annotations from 357 articles\n"
     ]
    }
   ],
   "source": [
    "# loading gold labels, articles ids and sentence ids from files *.task-TC.labels in the train labels folder \n",
    "ref_articles_id, ref_span_starts, ref_span_ends, train_gold_labels = read_predictions_from_file(train_labels_file)\n",
    "print(\"Loaded %d annotations from %d articles\" % (len(ref_span_starts), len(set(ref_articles_id))))\n",
    "\n",
    "# reading data from the development set\n",
    "dev_article_ids, dev_span_starts, dev_span_ends, dev_labels = read_predictions_from_file(dev_template_labels_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_data=[(id, [int(sps),int(spe)])for id, sps, spe in zip(ref_articles_id, ref_span_starts, ref_span_ends)]\n",
    "df=pd.DataFrame(in_data,columns=['ID','Span'])\n",
    "df['Sentence']=[read_span(id,span) for id,span in zip(df['ID'].tolist(),df['Span'].tolist())]\n",
    "df['Sentence']=df['Sentence'].apply(lambda x : clean(x))\n",
    "df['Span']=df['Span'].apply(lambda x : x[1]-x[0])\n",
    "df['Target']=train_gold_labels\n",
    "df=df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_data=[(id, [int(sps),int(spe)])for id, sps, spe in zip(dev_article_ids, dev_span_starts, dev_span_ends)]\n",
    "df_dev=pd.DataFrame(dev_data,columns=['ID','Span'])\n",
    "df_dev['Sentence']=[read_span(id,span,dev=True) for id,span in zip(df_dev['ID'].tolist(),df_dev['Span'].tolist())]\n",
    "df_dev['Sentence']=df_dev['Sentence'].apply(lambda x : clean(x))\n",
    "df_dev['Span']=df_dev['Span'].apply(lambda x : x[1]-x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tts_split(df=df,train,dev,size=500):\n",
    "    x1,x2,y1,y2=train_test_split(train,df['Target'],stratify=df['Target'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import StringIO\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import chi2\n",
    "from IPython.display import display\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_word = TfidfVectorizer(sublinear_tf=True, min_df=5,ngram_range=(1, 1),stop_words='english',analyzer='word')\n",
    "#tfidf_char = TfidfVectorizer(sublinear_tf=True, ngram_range=(2, 6),stop_words='english',analyzer='char')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_word = tfidf_word.fit_transform(df.Sentence).toarray()\n",
    "#fatures_char = tfidf_char.fit_transform(df.Sentence).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lr=LogisticRegression(penalty='l2', class_weight='balanced', solver=\"liblinear\", max_iter=500)\n",
    "model_lr.fit(X_train,Y_train)\n",
    "pred_lr=model_lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm=confusion_matrix(Y_test,pred_lr)\n",
    "cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "plt.figure(figsize = (10,8))\n",
    "sns.heatmap(cm,annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(Y_test,pred_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF=pd.concat([df,df_dev])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(sublinear_tf=True, min_df=5,ngram_range=(1, 3),stop_words='english')\n",
    "features = tfidf.fit_transform(DF.Sentence).toarray()\n",
    "features = np.append(features,DF['Span'].values.reshape(-1,1),axis=1)\n",
    "Train_X, Train_Y = features[:5780], DF[:5780]['Target']\n",
    "Test=features[5780:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lr=LogisticRegression(penalty='l2', class_weight='balanced', solver=\"liblinear\", max_iter=500)\n",
    "model_lr.fit(Train_X, Train_Y)\n",
    "pred_lr=model_lr.predict(Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### writing predictions to file\n",
    "with open(task_TC_output_file, \"w\") as fout:\n",
    "    for article_id, prediction, span_start, span_end in zip(dev_article_ids, pred_lr, dev_span_starts, dev_span_ends):\n",
    "        fout.write(\"%s\\t%s\\t%s\\t%s\\n\" % (article_id, prediction, span_start, span_end))\n",
    "print(\"Predictions written to file \" + task_TC_output_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
